# ğŸš€ AI Website Generator (Ollama + Next.js + FastAPI)

An AI-powered website generator that converts natural language prompts into fully functional, responsive websites using HTML, CSS, and JavaScript â€” all generated locally using Ollama (no paid APIs).

## âœ¨ Features

ğŸ§  AI-powered website generation from text prompts
ğŸ¨ Generates HTML, CSS, and JavaScript
ğŸ–¥ï¸ Live preview inside the browser using iframe
ğŸŒ™ Supports dark/light themes
ğŸ”’ Runs 100% locally using Ollama (no OpenAI / Gemini)
âš¡ FastAPI backend + Next.js frontend
ğŸ“± Responsive design output

## ğŸ›  Tech Stack
Frontend

Next.js (App Router)

React

Tailwind CSS

Backend

FastAPI

Python

Ollama (LLM runtime)

AI Model

qwen2.5:1.5b (lightweight, fast, local)

## ğŸ“‚ Project Structure

ai-website-generator/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ ollama_engine.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ venv/
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx
â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â””â”€â”€ globals.css
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ README.md

## âš™ï¸ Setup Instructions
1ï¸âƒ£ Install Ollama

Download and install Ollama from:
ğŸ‘‰ https://ollama.com

Pull the model:

ollama pull qwen2.5:1.5b

2ï¸âƒ£ Backend Setup (FastAPI)
cd backend
python -m venv venv
venv\Scripts\activate   # Windows
pip install -r requirements.txt


Start backend:

uvicorn main:app --reload


Backend runs at:

http://127.0.0.1:8000


Swagger Docs:

http://127.0.0.1:8000/docs

3ï¸âƒ£ Frontend Setup (Next.js)
cd frontend
npm install
npm run dev


Frontend runs at:

http://localhost:3000

## ğŸ§ª How It Works

User enters a prompt (e.g. â€œCreate a portfolio website for a photographer with dark themeâ€)

Frontend sends prompt to FastAPI

FastAPI calls Ollama locally

AI generates:

HTML

CSS

JavaScript

Code is parsed and injected into an iframe

Live website preview is shown instantly

âš™ï¸ Setup Instructions
1ï¸âƒ£ Install Ollama

Download and install Ollama from:
ğŸ‘‰ https://ollama.com

Pull the model:

ollama pull qwen2.5:1.5b

2ï¸âƒ£ Backend Setup (FastAPI)
cd backend
python -m venv venv
venv\Scripts\activate   # Windows
pip install -r requirements.txt


Start backend:

uvicorn main:app --reload


Backend runs at:

http://127.0.0.1:8000


Swagger Docs:

http://127.0.0.1:8000/docs

3ï¸âƒ£ Frontend Setup (Next.js)
cd frontend
npm install
npm run dev


Frontend runs at:

http://localhost:3000

ğŸ§ª How It Works

User enters a prompt (e.g. â€œCreate a portfolio website for a photographer with dark themeâ€)

Frontend sends prompt to FastAPI

FastAPI calls Ollama locally

AI generates:

HTML

CSS

JavaScript

Code is parsed and injected into an iframe

Live website preview is shown instantly


## ğŸ“¸ Example Prompt


## ğŸ§  Why Ollama?

âœ… Free & open-source

âœ… No API keys

âœ… Runs fully offline

âœ… Perfect for internships & demos

## ğŸš€ Future Improvements

Export website as ZIP

Save generated projects

Tailwind-only templates

Deploy to Vercel / Render

Component-based generation

Multi-page website support

## ğŸ‘¨â€ğŸ’» Author

Praneet Biswal
B.Tech Student | DevOps & AI Enthusiast

## ğŸ“œ License

This project is licensed under the MIT License.
